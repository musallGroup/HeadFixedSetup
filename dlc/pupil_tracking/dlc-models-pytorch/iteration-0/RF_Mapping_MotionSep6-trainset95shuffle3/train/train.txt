2024-09-12 11:38:19 Training with configuration:
2024-09-12 11:38:19 data:
2024-09-12 11:38:19   colormode: RGB
2024-09-12 11:38:19   inference:
2024-09-12 11:38:19     normalize_images: True
2024-09-12 11:38:19   train:
2024-09-12 11:38:19     affine:
2024-09-12 11:38:19       p: 0.5
2024-09-12 11:38:19       rotation: 30
2024-09-12 11:38:19       scaling: [1.0, 1.0]
2024-09-12 11:38:19       translation: 0
2024-09-12 11:38:19     collate:
2024-09-12 11:38:19       type: ResizeFromDataSizeCollate
2024-09-12 11:38:19       min_scale: 0.4
2024-09-12 11:38:19       max_scale: 1.0
2024-09-12 11:38:19       min_short_side: 128
2024-09-12 11:38:19       max_short_side: 1152
2024-09-12 11:38:19       multiple_of: 32
2024-09-12 11:38:19       to_square: False
2024-09-12 11:38:19     covering: False
2024-09-12 11:38:19     gaussian_noise: 12.75
2024-09-12 11:38:19     hist_eq: False
2024-09-12 11:38:19     motion_blur: False
2024-09-12 11:38:19     normalize_images: True
2024-09-12 11:38:19 device: auto
2024-09-12 11:38:19 metadata:
2024-09-12 11:38:19   project_path: D:\DeepLabCut_Projects\Elisa\RF_Mapping_Motion-Elisa-2024-09-06
2024-09-12 11:38:19   pose_config_path: D:\DeepLabCut_Projects\Elisa\RF_Mapping_Motion-Elisa-2024-09-06\dlc-models-pytorch\iteration-0\RF_Mapping_MotionSep6-trainset95shuffle3\train\pose_cfg.yaml
2024-09-12 11:38:19   bodyparts: ['UL(Upper_Lid)', 'DL(Down_Lid)', 'LL(Left_Lid)', 'RL(Right_Lid)', 'Top', 'Bottom', 'Left', 'Right', 'TR(Top_Right)', 'BR(Bottom_Right)', 'BL(Bottom_Left)', 'TL(Top_Left)', 'Centre']
2024-09-12 11:38:19   unique_bodyparts: []
2024-09-12 11:38:19   individuals: ['animal']
2024-09-12 11:38:19   with_identity: None
2024-09-12 11:38:19 method: bu
2024-09-12 11:38:19 model:
2024-09-12 11:38:19   backbone:
2024-09-12 11:38:19     type: ResNet
2024-09-12 11:38:19     model_name: resnet50_gn
2024-09-12 11:38:19     output_stride: 16
2024-09-12 11:38:19     freeze_bn_stats: True
2024-09-12 11:38:19     freeze_bn_weights: False
2024-09-12 11:38:19   backbone_output_channels: 2048
2024-09-12 11:38:19   heads:
2024-09-12 11:38:19     bodypart:
2024-09-12 11:38:19       type: HeatmapHead
2024-09-12 11:38:19       weight_init: normal
2024-09-12 11:38:19       predictor:
2024-09-12 11:38:19         type: HeatmapPredictor
2024-09-12 11:38:19         apply_sigmoid: False
2024-09-12 11:38:19         clip_scores: True
2024-09-12 11:38:19         location_refinement: True
2024-09-12 11:38:19         locref_std: 7.2801
2024-09-12 11:38:19       target_generator:
2024-09-12 11:38:19         type: HeatmapGaussianGenerator
2024-09-12 11:38:19         num_heatmaps: 13
2024-09-12 11:38:19         pos_dist_thresh: 17
2024-09-12 11:38:19         heatmap_mode: KEYPOINT
2024-09-12 11:38:19         generate_locref: True
2024-09-12 11:38:19         locref_std: 7.2801
2024-09-12 11:38:19       criterion:
2024-09-12 11:38:19         heatmap:
2024-09-12 11:38:19           type: WeightedMSECriterion
2024-09-12 11:38:19           weight: 1.0
2024-09-12 11:38:19         locref:
2024-09-12 11:38:19           type: WeightedHuberCriterion
2024-09-12 11:38:19           weight: 0.05
2024-09-12 11:38:19       heatmap_config:
2024-09-12 11:38:19         channels: [2048, 13]
2024-09-12 11:38:19         kernel_size: [3]
2024-09-12 11:38:19         strides: [2]
2024-09-12 11:38:19       locref_config:
2024-09-12 11:38:19         channels: [2048, 26]
2024-09-12 11:38:19         kernel_size: [3]
2024-09-12 11:38:19         strides: [2]
2024-09-12 11:38:19 net_type: resnet_50
2024-09-12 11:38:19 runner:
2024-09-12 11:38:19   type: PoseTrainingRunner
2024-09-12 11:38:19   gpus: None
2024-09-12 11:38:19   key_metric: test.mAP
2024-09-12 11:38:19   key_metric_asc: True
2024-09-12 11:38:19   eval_interval: 10
2024-09-12 11:38:19   optimizer:
2024-09-12 11:38:19     type: AdamW
2024-09-12 11:38:19     params:
2024-09-12 11:38:19       lr: 0.0001
2024-09-12 11:38:19   scheduler:
2024-09-12 11:38:19     type: LRListScheduler
2024-09-12 11:38:19     params:
2024-09-12 11:38:19       lr_list: [[1e-05], [1e-06]]
2024-09-12 11:38:19       milestones: [160, 190]
2024-09-12 11:38:19   snapshots:
2024-09-12 11:38:19     max_snapshots: 5
2024-09-12 11:38:19     save_epochs: 50
2024-09-12 11:38:19     save_optimizer_state: False
2024-09-12 11:38:19 train_settings:
2024-09-12 11:38:19   batch_size: 1
2024-09-12 11:38:19   dataloader_workers: 0
2024-09-12 11:38:19   dataloader_pin_memory: True
2024-09-12 11:38:19   display_iters: 1000
2024-09-12 11:38:19   epochs: 200
2024-09-12 11:38:19   seed: 42
2024-09-12 11:38:19 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2024-09-12 11:38:20 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-09-12 11:38:20 Data Transforms:
2024-09-12 11:38:20   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2024-09-12 11:38:20   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2024-09-12 11:38:20 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2024-09-12 11:38:20 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2024-09-12 11:38:20 Using 372 images and 20 for testing
2024-09-12 11:38:20 
Starting pose model training...
--------------------------------------------------
2024-09-12 11:40:19 Epoch 1/200 (lr=0.0001), train loss 0.00504
2024-09-12 11:42:04 Epoch 2/200 (lr=0.0001), train loss 0.00232
2024-09-12 11:43:50 Epoch 3/200 (lr=0.0001), train loss 0.00166
2024-09-12 11:45:37 Epoch 4/200 (lr=0.0001), train loss 0.00158
2024-09-12 11:47:22 Epoch 5/200 (lr=0.0001), train loss 0.00149
2024-09-12 11:49:05 Epoch 6/200 (lr=0.0001), train loss 0.00137
2024-09-12 11:50:52 Epoch 7/200 (lr=0.0001), train loss 0.00131
2024-09-12 11:52:41 Epoch 8/200 (lr=0.0001), train loss 0.00123
2024-09-12 11:54:27 Epoch 9/200 (lr=0.0001), train loss 0.00115
2024-09-12 11:56:12 Training for epoch 10 done, starting evaluation
2024-09-12 11:56:15 Epoch 10 performance:
2024-09-12 11:56:15 metrics/test.rmse:  3.560
2024-09-12 11:56:15 metrics/test.rmse_pcutoff:3.553
2024-09-12 11:56:15 metrics/test.mAP:   87.869
2024-09-12 11:56:15 metrics/test.mAR:   88.500
2024-09-12 11:56:15 metrics/test.rmse_detections:3.560
2024-09-12 11:56:15 metrics/test.rmse_detections_pcutoff:3.553
2024-09-12 11:56:15 Epoch 10/200 (lr=0.0001), train loss 0.00112, valid loss 0.00208
2024-09-12 11:58:01 Epoch 11/200 (lr=0.0001), train loss 0.00113
2024-09-12 11:59:49 Epoch 12/200 (lr=0.0001), train loss 0.00115
2024-09-12 12:01:35 Epoch 13/200 (lr=0.0001), train loss 0.00102
2024-09-12 12:03:21 Epoch 14/200 (lr=0.0001), train loss 0.00105
2024-09-12 12:05:08 Epoch 15/200 (lr=0.0001), train loss 0.00099
2024-09-12 12:06:53 Epoch 16/200 (lr=0.0001), train loss 0.00101
2024-09-12 12:08:37 Epoch 17/200 (lr=0.0001), train loss 0.00093
2024-09-12 12:10:23 Epoch 18/200 (lr=0.0001), train loss 0.00091
2024-09-12 12:12:10 Epoch 19/200 (lr=0.0001), train loss 0.00101
2024-09-12 12:13:57 Training for epoch 20 done, starting evaluation
2024-09-12 12:14:00 Epoch 20 performance:
2024-09-12 12:14:00 metrics/test.rmse:  2.993
2024-09-12 12:14:00 metrics/test.rmse_pcutoff:2.964
2024-09-12 12:14:00 metrics/test.mAP:   90.214
2024-09-12 12:14:00 metrics/test.mAR:   90.500
2024-09-12 12:14:00 metrics/test.rmse_detections:2.993
2024-09-12 12:14:00 metrics/test.rmse_detections_pcutoff:2.964
2024-09-12 12:14:00 Epoch 20/200 (lr=0.0001), train loss 0.00099, valid loss 0.00180
2024-09-12 12:15:48 Epoch 21/200 (lr=0.0001), train loss 0.00089
2024-09-12 12:17:33 Epoch 22/200 (lr=0.0001), train loss 0.00095
2024-09-12 12:19:20 Epoch 23/200 (lr=0.0001), train loss 0.00087
2024-09-12 12:21:08 Epoch 24/200 (lr=0.0001), train loss 0.00091
2024-09-12 12:22:56 Epoch 25/200 (lr=0.0001), train loss 0.00088
2024-09-12 12:24:42 Epoch 26/200 (lr=0.0001), train loss 0.00084
2024-09-12 12:26:27 Epoch 27/200 (lr=0.0001), train loss 0.00084
2024-09-12 12:28:15 Epoch 28/200 (lr=0.0001), train loss 0.00085
2024-09-12 12:30:02 Epoch 29/200 (lr=0.0001), train loss 0.00081
2024-09-12 12:31:50 Training for epoch 30 done, starting evaluation
2024-09-12 12:31:53 Epoch 30 performance:
2024-09-12 12:31:53 metrics/test.rmse:  3.238
2024-09-12 12:31:53 metrics/test.rmse_pcutoff:3.221
2024-09-12 12:31:53 metrics/test.mAP:   88.311
2024-09-12 12:31:53 metrics/test.mAR:   89.000
2024-09-12 12:31:53 metrics/test.rmse_detections:3.238
2024-09-12 12:31:53 metrics/test.rmse_detections_pcutoff:3.221
2024-09-12 12:31:53 Epoch 30/200 (lr=0.0001), train loss 0.00076, valid loss 0.00178
2024-09-12 12:33:39 Epoch 31/200 (lr=0.0001), train loss 0.00080
2024-09-12 12:35:25 Epoch 32/200 (lr=0.0001), train loss 0.00082
2024-09-12 12:37:16 Epoch 33/200 (lr=0.0001), train loss 0.00073
2024-09-12 12:39:07 Epoch 34/200 (lr=0.0001), train loss 0.00075
2024-09-12 12:40:52 Epoch 35/200 (lr=0.0001), train loss 0.00077
2024-09-12 12:42:41 Epoch 36/200 (lr=0.0001), train loss 0.00074
2024-09-12 12:44:24 Epoch 37/200 (lr=0.0001), train loss 0.00071
2024-09-12 12:46:15 Epoch 38/200 (lr=0.0001), train loss 0.00085
2024-09-12 12:48:01 Epoch 39/200 (lr=0.0001), train loss 0.00077
2024-09-12 12:49:49 Training for epoch 40 done, starting evaluation
2024-09-12 12:49:52 Epoch 40 performance:
2024-09-12 12:49:52 metrics/test.rmse:  2.883
2024-09-12 12:49:52 metrics/test.rmse_pcutoff:2.883
2024-09-12 12:49:52 metrics/test.mAP:   91.058
2024-09-12 12:49:52 metrics/test.mAR:   91.500
2024-09-12 12:49:52 metrics/test.rmse_detections:2.883
2024-09-12 12:49:52 metrics/test.rmse_detections_pcutoff:2.883
2024-09-12 12:49:52 Epoch 40/200 (lr=0.0001), train loss 0.00074, valid loss 0.00162
2024-09-12 12:51:38 Epoch 41/200 (lr=0.0001), train loss 0.00071
2024-09-12 12:53:25 Epoch 42/200 (lr=0.0001), train loss 0.00073
2024-09-12 12:55:11 Epoch 43/200 (lr=0.0001), train loss 0.00076
2024-09-12 12:56:55 Epoch 44/200 (lr=0.0001), train loss 0.00069
2024-09-12 12:58:45 Epoch 45/200 (lr=0.0001), train loss 0.00068
2024-09-12 13:00:29 Epoch 46/200 (lr=0.0001), train loss 0.00066
2024-09-12 13:02:13 Epoch 47/200 (lr=0.0001), train loss 0.00068
2024-09-12 13:04:00 Epoch 48/200 (lr=0.0001), train loss 0.00069
2024-09-12 13:05:47 Epoch 49/200 (lr=0.0001), train loss 0.00065
2024-09-12 13:07:31 Training for epoch 50 done, starting evaluation
2024-09-12 13:07:34 Epoch 50 performance:
2024-09-12 13:07:34 metrics/test.rmse:  2.708
2024-09-12 13:07:34 metrics/test.rmse_pcutoff:2.694
2024-09-12 13:07:34 metrics/test.mAP:   91.188
2024-09-12 13:07:34 metrics/test.mAR:   91.500
2024-09-12 13:07:34 metrics/test.rmse_detections:2.708
2024-09-12 13:07:34 metrics/test.rmse_detections_pcutoff:2.694
2024-09-12 13:07:34 Epoch 50/200 (lr=0.0001), train loss 0.00069, valid loss 0.00152
2024-09-12 13:09:20 Epoch 51/200 (lr=0.0001), train loss 0.00068
2024-09-12 13:11:08 Epoch 52/200 (lr=0.0001), train loss 0.00067
2024-09-12 13:12:51 Epoch 53/200 (lr=0.0001), train loss 0.00066
2024-09-12 13:14:37 Epoch 54/200 (lr=0.0001), train loss 0.00062
2024-09-12 13:16:22 Epoch 55/200 (lr=0.0001), train loss 0.00062
2024-09-12 13:18:09 Epoch 56/200 (lr=0.0001), train loss 0.00063
2024-09-12 13:19:57 Epoch 57/200 (lr=0.0001), train loss 0.00061
2024-09-12 13:21:43 Epoch 58/200 (lr=0.0001), train loss 0.00062
2024-09-12 13:23:31 Epoch 59/200 (lr=0.0001), train loss 0.00065
2024-09-12 13:25:13 Training for epoch 60 done, starting evaluation
2024-09-12 13:25:15 Epoch 60 performance:
2024-09-12 13:25:15 metrics/test.rmse:  2.829
2024-09-12 13:25:15 metrics/test.rmse_pcutoff:2.682
2024-09-12 13:25:15 metrics/test.mAP:   90.000
2024-09-12 13:25:15 metrics/test.mAR:   90.000
2024-09-12 13:25:15 metrics/test.rmse_detections:2.829
2024-09-12 13:25:15 metrics/test.rmse_detections_pcutoff:2.682
2024-09-12 13:25:15 Epoch 60/200 (lr=0.0001), train loss 0.00058, valid loss 0.00160
2024-09-12 13:27:03 Epoch 61/200 (lr=0.0001), train loss 0.00059
2024-09-12 13:28:48 Epoch 62/200 (lr=0.0001), train loss 0.00061
2024-09-12 13:30:36 Epoch 63/200 (lr=0.0001), train loss 0.00059
2024-09-12 13:32:22 Epoch 64/200 (lr=0.0001), train loss 0.00065
2024-09-12 13:34:09 Epoch 65/200 (lr=0.0001), train loss 0.00061
2024-09-12 13:35:57 Epoch 66/200 (lr=0.0001), train loss 0.00061
2024-09-12 13:37:43 Epoch 67/200 (lr=0.0001), train loss 0.00061
2024-09-12 13:39:28 Epoch 68/200 (lr=0.0001), train loss 0.00056
2024-09-12 13:41:14 Epoch 69/200 (lr=0.0001), train loss 0.00057
2024-09-12 13:43:00 Training for epoch 70 done, starting evaluation
2024-09-12 13:43:03 Epoch 70 performance:
2024-09-12 13:43:03 metrics/test.rmse:  2.788
2024-09-12 13:43:03 metrics/test.rmse_pcutoff:2.734
2024-09-12 13:43:03 metrics/test.mAP:   90.006
2024-09-12 13:43:03 metrics/test.mAR:   90.500
2024-09-12 13:43:03 metrics/test.rmse_detections:2.788
2024-09-12 13:43:03 metrics/test.rmse_detections_pcutoff:2.734
2024-09-12 13:43:03 Epoch 70/200 (lr=0.0001), train loss 0.00055, valid loss 0.00162
2024-09-12 13:44:50 Epoch 71/200 (lr=0.0001), train loss 0.00058
2024-09-12 13:46:34 Epoch 72/200 (lr=0.0001), train loss 0.00059
2024-09-12 13:48:23 Epoch 73/200 (lr=0.0001), train loss 0.00058
2024-09-12 13:50:07 Epoch 74/200 (lr=0.0001), train loss 0.00054
2024-09-12 13:51:55 Epoch 75/200 (lr=0.0001), train loss 0.00058
2024-09-12 13:53:40 Epoch 76/200 (lr=0.0001), train loss 0.00055
2024-09-12 13:55:29 Epoch 77/200 (lr=0.0001), train loss 0.00059
2024-09-12 13:57:16 Epoch 78/200 (lr=0.0001), train loss 0.00056
2024-09-12 13:59:04 Epoch 79/200 (lr=0.0001), train loss 0.00053
2024-09-12 14:00:50 Training for epoch 80 done, starting evaluation
2024-09-12 14:00:53 Epoch 80 performance:
2024-09-12 14:00:53 metrics/test.rmse:  2.834
2024-09-12 14:00:53 metrics/test.rmse_pcutoff:2.812
2024-09-12 14:00:53 metrics/test.mAP:   89.330
2024-09-12 14:00:53 metrics/test.mAR:   89.500
2024-09-12 14:00:53 metrics/test.rmse_detections:2.834
2024-09-12 14:00:53 metrics/test.rmse_detections_pcutoff:2.812
2024-09-12 14:00:53 Epoch 80/200 (lr=0.0001), train loss 0.00055, valid loss 0.00173
2024-09-12 14:02:38 Epoch 81/200 (lr=0.0001), train loss 0.00050
2024-09-12 14:04:21 Epoch 82/200 (lr=0.0001), train loss 0.00053
2024-09-12 14:06:04 Epoch 83/200 (lr=0.0001), train loss 0.00052
2024-09-12 14:07:51 Epoch 84/200 (lr=0.0001), train loss 0.00057
2024-09-12 14:09:34 Epoch 85/200 (lr=0.0001), train loss 0.00054
2024-09-12 14:11:20 Epoch 86/200 (lr=0.0001), train loss 0.00052
2024-09-12 14:13:08 Epoch 87/200 (lr=0.0001), train loss 0.00051
2024-09-12 14:14:57 Epoch 88/200 (lr=0.0001), train loss 0.00052
2024-09-12 14:16:45 Epoch 89/200 (lr=0.0001), train loss 0.00052
2024-09-12 14:18:32 Training for epoch 90 done, starting evaluation
2024-09-12 14:18:35 Epoch 90 performance:
2024-09-12 14:18:35 metrics/test.rmse:  2.920
2024-09-12 14:18:35 metrics/test.rmse_pcutoff:2.901
2024-09-12 14:18:35 metrics/test.mAP:   91.557
2024-09-12 14:18:35 metrics/test.mAR:   92.000
2024-09-12 14:18:35 metrics/test.rmse_detections:2.920
2024-09-12 14:18:35 metrics/test.rmse_detections_pcutoff:2.901
2024-09-12 14:18:35 Epoch 90/200 (lr=0.0001), train loss 0.00054, valid loss 0.00177
2024-09-12 14:20:21 Epoch 91/200 (lr=0.0001), train loss 0.00051
2024-09-12 14:22:12 Epoch 92/200 (lr=0.0001), train loss 0.00050
2024-09-12 14:24:02 Epoch 93/200 (lr=0.0001), train loss 0.00049
2024-09-12 14:25:50 Epoch 94/200 (lr=0.0001), train loss 0.00052
2024-09-12 14:27:37 Epoch 95/200 (lr=0.0001), train loss 0.00048
2024-09-12 14:29:26 Epoch 96/200 (lr=0.0001), train loss 0.00048
2024-09-12 14:31:13 Epoch 97/200 (lr=0.0001), train loss 0.00050
2024-09-12 14:32:58 Epoch 98/200 (lr=0.0001), train loss 0.00049
2024-09-12 14:34:46 Epoch 99/200 (lr=0.0001), train loss 0.00051
2024-09-12 14:36:31 Training for epoch 100 done, starting evaluation
2024-09-12 14:36:34 Epoch 100 performance:
2024-09-12 14:36:34 metrics/test.rmse:  2.882
2024-09-12 14:36:34 metrics/test.rmse_pcutoff:2.844
2024-09-12 14:36:34 metrics/test.mAP:   90.610
2024-09-12 14:36:34 metrics/test.mAR:   92.000
2024-09-12 14:36:34 metrics/test.rmse_detections:2.882
2024-09-12 14:36:34 metrics/test.rmse_detections_pcutoff:2.844
2024-09-12 14:36:34 Epoch 100/200 (lr=0.0001), train loss 0.00052, valid loss 0.00179
2024-09-12 14:38:21 Epoch 101/200 (lr=0.0001), train loss 0.00048
2024-09-12 14:40:08 Epoch 102/200 (lr=0.0001), train loss 0.00046
2024-09-12 14:41:57 Epoch 103/200 (lr=0.0001), train loss 0.00048
2024-09-12 14:43:41 Epoch 104/200 (lr=0.0001), train loss 0.00047
2024-09-12 14:45:27 Epoch 105/200 (lr=0.0001), train loss 0.00050
2024-09-12 14:47:13 Epoch 106/200 (lr=0.0001), train loss 0.00049
2024-09-12 14:49:01 Epoch 107/200 (lr=0.0001), train loss 0.00048
2024-09-12 14:50:47 Epoch 108/200 (lr=0.0001), train loss 0.00045
2024-09-12 14:52:37 Epoch 109/200 (lr=0.0001), train loss 0.00049
2024-09-12 14:54:21 Training for epoch 110 done, starting evaluation
2024-09-12 14:54:24 Epoch 110 performance:
2024-09-12 14:54:24 metrics/test.rmse:  2.973
2024-09-12 14:54:24 metrics/test.rmse_pcutoff:2.973
2024-09-12 14:54:24 metrics/test.mAP:   91.902
2024-09-12 14:54:24 metrics/test.mAR:   92.500
2024-09-12 14:54:24 metrics/test.rmse_detections:2.973
2024-09-12 14:54:24 metrics/test.rmse_detections_pcutoff:2.973
2024-09-12 14:54:24 Epoch 110/200 (lr=0.0001), train loss 0.00045, valid loss 0.00175
2024-09-12 14:56:08 Epoch 111/200 (lr=0.0001), train loss 0.00048
2024-09-12 14:57:58 Epoch 112/200 (lr=0.0001), train loss 0.00046
2024-09-12 14:59:42 Epoch 113/200 (lr=0.0001), train loss 0.00045
2024-09-12 15:01:28 Epoch 114/200 (lr=0.0001), train loss 0.00050
2024-09-12 15:03:17 Epoch 115/200 (lr=0.0001), train loss 0.00047
2024-09-12 15:05:04 Epoch 116/200 (lr=0.0001), train loss 0.00044
2024-09-12 15:06:48 Epoch 117/200 (lr=0.0001), train loss 0.00042
2024-09-12 15:08:34 Epoch 118/200 (lr=0.0001), train loss 0.00047
2024-09-12 15:10:18 Epoch 119/200 (lr=0.0001), train loss 0.00044
2024-09-12 15:12:01 Training for epoch 120 done, starting evaluation
2024-09-12 15:12:04 Epoch 120 performance:
2024-09-12 15:12:04 metrics/test.rmse:  2.839
2024-09-12 15:12:04 metrics/test.rmse_pcutoff:2.839
2024-09-12 15:12:04 metrics/test.mAP:   92.324
2024-09-12 15:12:04 metrics/test.mAR:   93.000
2024-09-12 15:12:04 metrics/test.rmse_detections:2.839
2024-09-12 15:12:04 metrics/test.rmse_detections_pcutoff:2.839
2024-09-12 15:12:04 Epoch 120/200 (lr=0.0001), train loss 0.00044, valid loss 0.00163
2024-09-12 15:13:49 Epoch 121/200 (lr=0.0001), train loss 0.00045
2024-09-12 15:15:35 Epoch 122/200 (lr=0.0001), train loss 0.00043
2024-09-12 15:17:24 Epoch 123/200 (lr=0.0001), train loss 0.00044
2024-09-12 15:19:08 Epoch 124/200 (lr=0.0001), train loss 0.00044
2024-09-12 15:20:51 Epoch 125/200 (lr=0.0001), train loss 0.00041
2024-09-12 15:22:38 Epoch 126/200 (lr=0.0001), train loss 0.00043
2024-09-12 15:24:24 Epoch 127/200 (lr=0.0001), train loss 0.00043
2024-09-12 15:26:14 Epoch 128/200 (lr=0.0001), train loss 0.00045
2024-09-12 15:27:56 Epoch 129/200 (lr=0.0001), train loss 0.00041
2024-09-12 15:29:43 Training for epoch 130 done, starting evaluation
2024-09-12 15:29:46 Epoch 130 performance:
2024-09-12 15:29:46 metrics/test.rmse:  2.839
2024-09-12 15:29:46 metrics/test.rmse_pcutoff:2.809
2024-09-12 15:29:46 metrics/test.mAP:   91.980
2024-09-12 15:29:46 metrics/test.mAR:   92.500
2024-09-12 15:29:46 metrics/test.rmse_detections:2.839
2024-09-12 15:29:46 metrics/test.rmse_detections_pcutoff:2.809
2024-09-12 15:29:46 Epoch 130/200 (lr=0.0001), train loss 0.00045, valid loss 0.00171
2024-09-12 15:31:32 Epoch 131/200 (lr=0.0001), train loss 0.00044
2024-09-12 15:33:16 Epoch 132/200 (lr=0.0001), train loss 0.00045
2024-09-12 15:35:00 Epoch 133/200 (lr=0.0001), train loss 0.00047
2024-09-12 15:36:48 Epoch 134/200 (lr=0.0001), train loss 0.00044
2024-09-12 15:38:35 Epoch 135/200 (lr=0.0001), train loss 0.00042
2024-09-12 15:40:21 Epoch 136/200 (lr=0.0001), train loss 0.00041
2024-09-12 15:42:06 Epoch 137/200 (lr=0.0001), train loss 0.00039
2024-09-12 15:43:54 Epoch 138/200 (lr=0.0001), train loss 0.00040
2024-09-12 15:45:41 Epoch 139/200 (lr=0.0001), train loss 0.00042
2024-09-12 15:47:31 Training for epoch 140 done, starting evaluation
2024-09-12 15:47:33 Epoch 140 performance:
2024-09-12 15:47:33 metrics/test.rmse:  2.710
2024-09-12 15:47:33 metrics/test.rmse_pcutoff:2.710
2024-09-12 15:47:33 metrics/test.mAP:   90.547
2024-09-12 15:47:33 metrics/test.mAR:   91.000
2024-09-12 15:47:33 metrics/test.rmse_detections:2.710
2024-09-12 15:47:33 metrics/test.rmse_detections_pcutoff:2.710
2024-09-12 15:47:34 Epoch 140/200 (lr=0.0001), train loss 0.00041, valid loss 0.00164
2024-09-12 15:49:20 Epoch 141/200 (lr=0.0001), train loss 0.00040
2024-09-12 15:51:06 Epoch 142/200 (lr=0.0001), train loss 0.00048
2024-09-12 15:52:57 Epoch 143/200 (lr=0.0001), train loss 0.00045
2024-09-12 15:54:43 Epoch 144/200 (lr=0.0001), train loss 0.00041
2024-09-12 15:56:27 Epoch 145/200 (lr=0.0001), train loss 0.00040
2024-09-12 15:58:08 Epoch 146/200 (lr=0.0001), train loss 0.00038
2024-09-12 15:59:56 Epoch 147/200 (lr=0.0001), train loss 0.00040
2024-09-12 16:01:46 Epoch 148/200 (lr=0.0001), train loss 0.00044
2024-09-12 16:03:34 Epoch 149/200 (lr=0.0001), train loss 0.00042
2024-09-12 16:05:21 Training for epoch 150 done, starting evaluation
2024-09-12 16:05:24 Epoch 150 performance:
2024-09-12 16:05:24 metrics/test.rmse:  2.830
2024-09-12 16:05:24 metrics/test.rmse_pcutoff:2.682
2024-09-12 16:05:24 metrics/test.mAP:   90.000
2024-09-12 16:05:24 metrics/test.mAR:   90.000
2024-09-12 16:05:24 metrics/test.rmse_detections:2.830
2024-09-12 16:05:24 metrics/test.rmse_detections_pcutoff:2.682
2024-09-12 16:05:24 Epoch 150/200 (lr=0.0001), train loss 0.00043, valid loss 0.00183
2024-09-12 16:07:06 Epoch 151/200 (lr=0.0001), train loss 0.00039
2024-09-12 16:08:54 Epoch 152/200 (lr=0.0001), train loss 0.00039
2024-09-12 16:10:40 Epoch 153/200 (lr=0.0001), train loss 0.00038
2024-09-12 16:12:23 Epoch 154/200 (lr=0.0001), train loss 0.00039
2024-09-12 16:14:05 Epoch 155/200 (lr=0.0001), train loss 0.00037
2024-09-12 16:15:53 Epoch 156/200 (lr=0.0001), train loss 0.00037
2024-09-12 16:17:39 Epoch 157/200 (lr=0.0001), train loss 0.00039
2024-09-12 16:19:26 Epoch 158/200 (lr=0.0001), train loss 0.00038
2024-09-12 16:21:13 Epoch 159/200 (lr=0.0001), train loss 0.00038
2024-09-12 16:23:02 Training for epoch 160 done, starting evaluation
2024-09-12 16:23:05 Epoch 160 performance:
2024-09-12 16:23:05 metrics/test.rmse:  2.816
2024-09-12 16:23:05 metrics/test.rmse_pcutoff:2.682
2024-09-12 16:23:05 metrics/test.mAP:   90.029
2024-09-12 16:23:05 metrics/test.mAR:   90.500
2024-09-12 16:23:05 metrics/test.rmse_detections:2.816
2024-09-12 16:23:05 metrics/test.rmse_detections_pcutoff:2.682
2024-09-12 16:23:05 Epoch 160/200 (lr=1e-05), train loss 0.00040, valid loss 0.00175
2024-09-12 16:24:51 Epoch 161/200 (lr=1e-05), train loss 0.00034
2024-09-12 16:26:39 Epoch 162/200 (lr=1e-05), train loss 0.00029
2024-09-12 16:28:26 Epoch 163/200 (lr=1e-05), train loss 0.00028
2024-09-12 16:30:10 Epoch 164/200 (lr=1e-05), train loss 0.00028
2024-09-12 16:31:53 Epoch 165/200 (lr=1e-05), train loss 0.00028
2024-09-12 16:33:38 Epoch 166/200 (lr=1e-05), train loss 0.00027
2024-09-12 16:35:25 Epoch 167/200 (lr=1e-05), train loss 0.00028
2024-09-12 16:37:08 Epoch 168/200 (lr=1e-05), train loss 0.00026
2024-09-12 16:38:55 Epoch 169/200 (lr=1e-05), train loss 0.00028
2024-09-12 16:40:39 Training for epoch 170 done, starting evaluation
2024-09-12 16:40:41 Epoch 170 performance:
2024-09-12 16:40:41 metrics/test.rmse:  2.697
2024-09-12 16:40:41 metrics/test.rmse_pcutoff:2.697
2024-09-12 16:40:41 metrics/test.mAP:   91.980
2024-09-12 16:40:41 metrics/test.mAR:   92.500
2024-09-12 16:40:41 metrics/test.rmse_detections:2.697
2024-09-12 16:40:41 metrics/test.rmse_detections_pcutoff:2.697
2024-09-12 16:40:41 Epoch 170/200 (lr=1e-05), train loss 0.00027, valid loss 0.00167
2024-09-12 16:42:26 Epoch 171/200 (lr=1e-05), train loss 0.00027
2024-09-12 16:44:12 Epoch 172/200 (lr=1e-05), train loss 0.00025
2024-09-12 16:45:58 Epoch 173/200 (lr=1e-05), train loss 0.00026
2024-09-12 16:47:44 Epoch 174/200 (lr=1e-05), train loss 0.00027
2024-09-12 16:49:29 Epoch 175/200 (lr=1e-05), train loss 0.00026
2024-09-12 16:51:15 Epoch 176/200 (lr=1e-05), train loss 0.00027
2024-09-12 16:53:00 Epoch 177/200 (lr=1e-05), train loss 0.00025
2024-09-12 16:54:46 Epoch 178/200 (lr=1e-05), train loss 0.00025
2024-09-12 16:56:31 Epoch 179/200 (lr=1e-05), train loss 0.00025
2024-09-12 16:58:13 Training for epoch 180 done, starting evaluation
2024-09-12 16:58:16 Epoch 180 performance:
2024-09-12 16:58:16 metrics/test.rmse:  2.696
2024-09-12 16:58:16 metrics/test.rmse_pcutoff:2.696
2024-09-12 16:58:16 metrics/test.mAP:   91.980
2024-09-12 16:58:16 metrics/test.mAR:   92.500
2024-09-12 16:58:16 metrics/test.rmse_detections:2.696
2024-09-12 16:58:16 metrics/test.rmse_detections_pcutoff:2.696
2024-09-12 16:58:16 Epoch 180/200 (lr=1e-05), train loss 0.00024, valid loss 0.00168
2024-09-12 17:00:04 Epoch 181/200 (lr=1e-05), train loss 0.00026
2024-09-12 17:01:52 Epoch 182/200 (lr=1e-05), train loss 0.00026
2024-09-12 17:03:36 Epoch 183/200 (lr=1e-05), train loss 0.00025
2024-09-12 17:05:20 Epoch 184/200 (lr=1e-05), train loss 0.00024
2024-09-12 17:07:07 Epoch 185/200 (lr=1e-05), train loss 0.00025
2024-09-12 17:08:53 Epoch 186/200 (lr=1e-05), train loss 0.00025
2024-09-12 17:10:39 Epoch 187/200 (lr=1e-05), train loss 0.00025
2024-09-12 17:12:25 Epoch 188/200 (lr=1e-05), train loss 0.00025
2024-09-12 17:14:14 Epoch 189/200 (lr=1e-05), train loss 0.00025
2024-09-12 17:16:01 Training for epoch 190 done, starting evaluation
2024-09-12 17:16:04 Epoch 190 performance:
2024-09-12 17:16:04 metrics/test.rmse:  2.678
2024-09-12 17:16:04 metrics/test.rmse_pcutoff:2.678
2024-09-12 17:16:04 metrics/test.mAP:   91.980
2024-09-12 17:16:04 metrics/test.mAR:   92.500
2024-09-12 17:16:04 metrics/test.rmse_detections:2.678
2024-09-12 17:16:04 metrics/test.rmse_detections_pcutoff:2.678
2024-09-12 17:16:04 Epoch 190/200 (lr=1e-06), train loss 0.00026, valid loss 0.00168
2024-09-12 17:17:49 Epoch 191/200 (lr=1e-06), train loss 0.00024
2024-09-12 17:19:38 Epoch 192/200 (lr=1e-06), train loss 0.00024
2024-09-12 17:21:22 Epoch 193/200 (lr=1e-06), train loss 0.00023
2024-09-12 17:23:05 Epoch 194/200 (lr=1e-06), train loss 0.00023
2024-09-12 17:24:54 Epoch 195/200 (lr=1e-06), train loss 0.00024
2024-09-12 17:26:39 Epoch 196/200 (lr=1e-06), train loss 0.00023
2024-09-12 17:28:26 Epoch 197/200 (lr=1e-06), train loss 0.00023
2024-09-12 17:30:13 Epoch 198/200 (lr=1e-06), train loss 0.00023
2024-09-12 17:32:04 Epoch 199/200 (lr=1e-06), train loss 0.00024
2024-09-12 17:33:53 Training for epoch 200 done, starting evaluation
2024-09-12 17:33:56 Epoch 200 performance:
2024-09-12 17:33:56 metrics/test.rmse:  2.685
2024-09-12 17:33:56 metrics/test.rmse_pcutoff:2.685
2024-09-12 17:33:56 metrics/test.mAP:   91.980
2024-09-12 17:33:56 metrics/test.mAR:   92.500
2024-09-12 17:33:56 metrics/test.rmse_detections:2.685
2024-09-12 17:33:56 metrics/test.rmse_detections_pcutoff:2.685
2024-09-12 17:33:56 Epoch 200/200 (lr=1e-06), train loss 0.00023, valid loss 0.00169
